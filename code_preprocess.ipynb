{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "from tree_sitter import Language, Parser\n",
    "from collections import Counter\n",
    "PY_LANGUAGE = Language('D:/python/final/jsonl/train\\python_train_0.jsonl/build/my-languages.so', 'python')\n",
    "parser = Parser()\n",
    "parser.set_language(PY_LANGUAGE)\n",
    "json_file=[]\n",
    "with open(\"./train/python_train_0.jsonl/python_train_0.jsonl\") as rf:\n",
    "    for line in rf.readlines():\n",
    "        dic = json.loads(line)\n",
    "        dic_ = {}\n",
    "        dic_[\"docstrings\"] = dic[\"docstring\"]\n",
    "        dic_[\"code_tokens\"] = dic[\"code_tokens\"]\n",
    "        dic_[\"code\"] = dic[\"code\"]\n",
    "        dic_[\"docstring_tokens\"] = dic[\"docstring_tokens\"]\n",
    "        json_file.append(dic_)\n",
    "\n",
    "\n",
    "def DFS_Tree(node):\n",
    "    if not node:\n",
    "        return []\n",
    "    stack = [node]\n",
    "    res = []\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        res.append(node.type)\n",
    "        for child in node.children:\n",
    "            stack.append(child)\n",
    "            res.append(child.type)\n",
    "    return res\n",
    "\n",
    "\n",
    "def BFS_Tree(node):\n",
    "    if node == None:\n",
    "        return []\n",
    "    node_list = []\n",
    "    nodes = []\n",
    "    node_list.append(node)\n",
    "    nodes.append(node.type)\n",
    "    while node_list:\n",
    "        node = node_list.pop(0)\n",
    "        for child in node.children:\n",
    "            node_list.append(child)\n",
    "            nodes.append(child.type)\n",
    "    return nodes\n",
    "\n",
    "def load_data(json_file):\n",
    "    pl = []\n",
    "    nl = []\n",
    "    num_examples = 0\n",
    "    idx = 0\n",
    "    for program in json_file:\n",
    "#         program[\"docstrings\"] = program[\"docstrings\"].strip()\n",
    "#         idx +=1\n",
    "#         print(idx)\n",
    "        nl.append([\"BOS\"] + nltk.word_tokenize(program[\"docstrings\"].lower()) + [\"EOS\"])\n",
    "        # split chinese sentence into characters\n",
    "        pl.append([\"BOS\"] + DFS_Tree(program[\"AST\"].root_node) + [\"EOS\"])\n",
    "    return nl, pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trains a k - nearest neighbors classifier for face recognition . # Loop through each person in the training set # Loop through each training image for the current person # If there are no people (or too many people) in a training image, skip the image. # Add face encoding for current image to the training set # Determine how many neighbors to use for weighting in the KNN classifier # Create and train the KNN classifier # Save the trained KNN classifier\n",
      "['BOS', 'trains', 'a', 'k', '-', 'nearest', 'neighbors', 'classifier', 'for', 'face', 'recognition', '.', '#', 'loop', 'through', 'each', 'person', 'in', 'the', 'training', 'set', '#', 'loop', 'through', 'each', 'training', 'image', 'for', 'the', 'current', 'person', '#', 'if', 'there', 'are', 'no', 'people', '(', 'or', 'too', 'many', 'people', ')', 'in', 'a', 'training', 'image', ',', 'skip', 'the', 'image', '.', '#', 'add', 'face', 'encoding', 'for', 'current', 'image', 'to', 'the', 'training', 'set', '#', 'determine', 'how', 'many', 'neighbors', 'to', 'use', 'for', 'weighting', 'in', 'the', 'knn', 'classifier', '#', 'create', 'and', 'train', 'the', 'knn', 'classifier', '#', 'save', 'the', 'trained', 'knn', 'classifier', 'EOS']\n",
      "['BOS', 'module', 'function_definition', 'function_definition', 'def', 'identifier', 'parameters', ':', 'block', 'block', 'expression_statement', 'expression_statement', 'expression_statement', 'comment', 'for_statement', 'comment', 'if_statement', 'comment', 'expression_statement', 'expression_statement', 'comment', 'if_statement', 'return_statement', 'return_statement', 'return', 'identifier', 'identifier', 'return', 'if_statement', 'if', 'comparison_operator', ':', 'block', 'block', 'with_statement', 'with_statement', 'with', 'with_clause', ':', 'block', 'block', 'expression_statement', 'expression_statement', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'identifier', ')', ')', 'identifier', ',', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', ':', 'with_clause', 'with_item', 'with_item', 'call', 'as', 'identifier', 'identifier', 'as', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'identifier', ',', 'string', ')', ')', 'string', '\"', '\"', '\"', '\"', ',', 'identifier', '(', 'identifier', 'with', ':', 'comparison_operator', 'identifier', 'is', 'not', 'none', 'none', 'not', 'is', 'identifier', 'if', 'comment', 'expression_statement', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'identifier', ')', ')', 'identifier', ',', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'keyword_argument', ',', 'keyword_argument', ',', 'keyword_argument', ')', ')', 'keyword_argument', 'identifier', '=', 'string', 'string', '\"', '\"', '\"', '\"', '=', 'identifier', ',', 'keyword_argument', 'identifier', '=', 'identifier', 'identifier', '=', 'identifier', ',', 'keyword_argument', 'identifier', '=', 'identifier', 'identifier', '=', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '=', 'identifier', 'comment', 'if_statement', 'if', 'comparison_operator', ':', 'block', 'block', 'expression_statement', 'if_statement', 'if_statement', 'if', 'identifier', ':', 'block', 'block', 'expression_statement', 'expression_statement', 'call', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'string', ',', 'identifier', ')', ')', 'identifier', ',', 'string', '\"', '\"', '\"', '\"', '(', 'identifier', ':', 'identifier', 'if', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'call', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '(', 'identifier', '(', 'identifier', '=', 'identifier', ':', 'comparison_operator', 'identifier', 'is', 'none', 'none', 'is', 'identifier', 'if', 'comment', 'for_statement', 'for', 'identifier', 'in', 'call', ':', 'block', 'block', 'if_statement', 'comment', 'for_statement', 'for_statement', 'for', 'identifier', 'in', 'call', ':', 'block', 'block', 'expression_statement', 'expression_statement', 'if_statement', 'if_statement', 'if', 'comparison_operator', ':', 'comment', 'block', 'else_clause', 'else_clause', 'else', ':', 'comment', 'block', 'block', 'expression_statement', 'expression_statement', 'expression_statement', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', 'expression_statement', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'subscript', ')', ')', 'subscript', 'call', '[', 'integer', ']', ']', 'integer', '[', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'keyword_argument', ')', ')', 'keyword_argument', 'identifier', '=', 'identifier', 'identifier', '=', 'identifier', ',', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', 'comment', ':', 'else', 'block', 'if_statement', 'if_statement', 'if', 'identifier', ':', 'block', 'block', 'expression_statement', 'expression_statement', 'call', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'conditional_expression', ')', ')', 'conditional_expression', 'string', 'if', 'comparison_operator', 'else', 'string', 'string', '\"', '\"', '\"', '\"', 'else', 'comparison_operator', 'call', '<', 'integer', 'integer', '<', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'identifier', 'if', 'string', '\"', '\"', '\"', '\"', ',', 'identifier', '(', 'attribute', 'string', '.', 'identifier', 'identifier', '.', 'string', '\"', '\"', '\"', '\"', '(', 'identifier', ':', 'identifier', 'if', 'comment', ':', 'comparison_operator', 'call', '!=', 'integer', 'integer', '!=', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'identifier', 'if', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '=', 'identifier', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '=', 'identifier', ':', 'call', 'identifier', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'identifier', ')', ')', 'identifier', ',', 'identifier', '(', 'attribute', 'attribute', '.', 'identifier', 'identifier', '.', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '(', 'identifier', 'in', 'identifier', 'for', 'comment', 'if_statement', 'if', 'not_operator', ':', 'block', 'block', 'continue_statement', 'continue_statement', 'continue', 'continue', ':', 'not_operator', 'not', 'call', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'call', ')', ')', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ',', 'identifier', ')', ')', 'identifier', ',', 'identifier', '(', 'attribute', 'attribute', '.', 'identifier', 'identifier', '.', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', '(', 'attribute', 'attribute', '.', 'identifier', 'identifier', '.', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', 'not', 'if', ':', 'call', 'attribute', 'argument_list', 'argument_list', '(', 'identifier', ')', ')', 'identifier', '(', 'attribute', 'identifier', '.', 'identifier', 'identifier', '.', 'identifier', 'in', 'identifier', 'for', 'comment', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'list', 'list', '[', ']', ']', '[', '=', 'identifier', 'expression_statement', 'assignment', 'assignment', 'identifier', '=', 'list', 'list', '[', ']', ']', '[', '=', 'identifier', 'expression_statement', 'string', 'string', '\"', '\"', '\"', '\"', ':', 'parameters', '(', 'identifier', ',', 'default_parameter', ',', 'default_parameter', ',', 'default_parameter', ',', 'default_parameter', ')', ')', 'default_parameter', 'identifier', '=', 'false', 'false', '=', 'identifier', ',', 'default_parameter', 'identifier', '=', 'string', 'string', '\"', '\"', '\"', '\"', '=', 'identifier', ',', 'default_parameter', 'identifier', '=', 'none', 'none', '=', 'identifier', ',', 'default_parameter', 'identifier', '=', 'none', 'none', '=', 'identifier', ',', 'identifier', '(', 'identifier', 'def', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(json_file)):\n",
    "\n",
    "    docstrings = []\n",
    "    code = json_file[idx][\"code\"]\n",
    "    for token in json_file[idx][\"code_tokens\"]:\n",
    "        if len(token) and token[0] == '#':\n",
    "            docstrings.append(token)\n",
    "            json_file[idx][\"code_tokens\"].remove(token)\n",
    "    json_file[idx][\"AST\"] = parser.parse(bytes(code, \"utf8\"))\n",
    "    json_file[idx][\"docstrings\"] = json_file[idx][\"docstring_tokens\"] + docstrings\n",
    "    nl = ' '.join(json_file[idx][\"docstrings\"])\n",
    "    json_file[idx][\"docstrings\"] = nl\n",
    "print(json_file[0][\"docstrings\"])\n",
    "# tree = parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "nl , pl = load_data(json_file)\n",
    "print(nl[0])\n",
    "print(pl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier': 2, '\"': 3, '(': 4, ')': 5, '.': 6, 'attribute': 7, ',': 8, 'call': 9, 'argument_list': 10, '=': 11, 'expression_statement': 12, 'string': 13, ':': 14, 'assignment': 15, 'block': 16, '[': 17, ']': 18, 'subscript': 19, 'if': 20, 'if_statement': 21, 'keyword_argument': 22, 'integer': 23, 'comment': 24, 'comparison_operator': 25, 'return_statement': 26, 'return': 27, 'none': 28, 'function_definition': 29, 'def': 30, 'parameters': 31, 'default_parameter': 32, 'in': 33, 'binary_operator': 34, 'not': 35, 'pair': 36, 'for': 37, 'else': 38, 'list': 39, 'BOS': 40, 'module': 41, 'EOS': 42, 'else_clause': 43, '{': 44, '}': 45, 'dictionary': 46, 'false': 47, '==': 48, 'for_statement': 49, 'boolean_operator': 50, 'not_operator': 51, 'is': 52, 'true': 53, '+': 54, 'escape_sequence': 55, 'tuple': 56, 'raise_statement': 57, 'raise': 58, '-': 59, 'pattern_list': 60, 'and': 61, '**': 62, 'parenthesized_expression': 63, 'except_clause': 64, 'except': 65, 'elif_clause': 66, 'elif': 67, '*': 68, 'try_statement': 69, 'try': 70, 'for_in_clause': 71, 'slice': 72, 'unary_operator': 73, 'float': 74, 'or': 75, 'list_comprehension': 76, 'type': 77, 'as': 78, 'augmented_assignment': 79, 'dictionary_splat': 80, '%': 81, 'concatenated_string': 82, '!=': 83, '+=': 84, 'dictionary_splat_pattern': 85, 'with_item': 86, 'with_statement': 87, 'with': 88, 'with_clause': 89, 'conditional_expression': 90, 'dotted_name': 91, 'lambda': 92, 'expression_list': 93, '>': 94, 'assert_statement': 95, 'assert': 96, '/': 97, 'continue_statement': 98, 'continue': 99, 'typed_parameter': 100, '<': 101, 'yield': 102, 'import': 103, 'typed_default_parameter': 104, '->': 105, 'list_splat': 106, 'generator_expression': 107, 'if_clause': 108, 'pass_statement': 109, 'pass': 110, 'while_statement': 111, 'while': 112, 'lambda_parameters': 113, 'from': 114, 'import_from_statement': 115, 'break_statement': 116, 'break': 117, 'tuple_pattern': 118, '>=': 119, 'list_splat_pattern': 120, '<=': 121, 'delete_statement': 122, 'del': 123, 'await': 124, 'interpolation': 125, '//': 126, 'dictionary_comprehension': 127, 'import_statement': 128, 'finally_clause': 129, 'finally': 130, '&': 131, 'relative_import': 132, 'import_prefix': 133, '-=': 134, '|': 135, 'aliased_import': 136, '*=': 137, 'async': 138, 'global_statement': 139, 'global': 140, '@': 141, 'decorator': 142, 'decorated_definition': 143, '|=': 144, '~': 145, 'print_statement': 146, 'print': 147, 'ellipsis': 148, 'set': 149, '/=': 150, 'set_comprehension': 151, '>>': 152, 'list_pattern': 153, '<<': 154, 'class_definition': 155, 'class': 156, '^': 157, '&=': 158, 'format_specifier': 159, 'chevron': 160, '//=': 161, '%=': 162, '^=': 163, '>>=': 164, '<<=': 165, 'ERROR': 166, 'format_expression': 167, 'nonlocal_statement': 168, 'nonlocal': 169, 'UNK': 0, 'PAD': 1} 170\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'en_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ca73e071143f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpl_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpl_total_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpl_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpl_total_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0minv_en_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0men_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0minv_cn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcn_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'en_dict' is not defined"
     ]
    }
   ],
   "source": [
    "UNK_IDX = 1\n",
    "PAD_IDX = 0\n",
    "def build_dict(sentences, max_words=50000):\n",
    "    word_count = Counter()\n",
    "    for sentence in sentences:\n",
    "        for s in sentence:\n",
    "            word_count[s] += 1\n",
    "    ls = word_count.most_common(max_words)\n",
    "    total_words = len(ls) + 2\n",
    "    word_dict = {w[0]: index+2 for index, w in enumerate(ls)}\n",
    "    word_dict[\"UNK\"] = UNK_IDX\n",
    "    word_dict[\"PAD\"] = PAD_IDX\n",
    "    return word_dict, total_words\n",
    "\n",
    "nl_dict, nl_total_words = build_dict(nl)\n",
    "pl_dict, pl_total_words = build_dict(pl)\n",
    "print(pl_dict, pl_total_words)\n",
    "inv_en_dict = {v: k for k, v in en_dict.items()}\n",
    "inv_cn_dict = {v: k for k, v in cn_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3689, 7, 611, 20, 1501, 1770, 1448, 14, 2346, 3499, 2, 4, 452, 348, 73, 6407, 17, 3, 186, 45, 4, 452, 348, 73, 186, 127, 14, 3, 90, 6407, 4, 18, 128, 38, 79, 2977, 15, 30, 709, 925, 2977, 16, 17, 7, 186, 127, 11, 459, 3, 127, 2, 4, 59, 2346, 553, 14, 90, 127, 8, 3, 186, 45, 4, 468, 538, 925, 1770, 8, 58, 14, 4759, 17, 3, 4760, 1448, 4, 53, 12, 492, 3, 4760, 1448, 4, 215, 3, 788, 4760, 1448, 6]\n",
      "BOS trains a k - nearest neighbors classifier for face recognition . # loop through each person in the training set # loop through each training image for the current person # if there are no people ( or too many people ) in a training image , skip the image . # add face encoding for current image to the training set # determine how many neighbors to use for weighting in the knn classifier # create and train the knn classifier # save the trained knn classifier EOS\n",
      "BOS module function_definition function_definition def identifier parameters : block block expression_statement expression_statement expression_statement comment for_statement comment if_statement comment expression_statement expression_statement comment if_statement return_statement return_statement return identifier identifier return if_statement if comparison_operator : block block with_statement with_statement with with_clause : block block expression_statement expression_statement call call attribute argument_list argument_list ( identifier , identifier ) ) identifier , identifier ( attribute identifier . identifier identifier . identifier : with_clause with_item with_item call as identifier identifier as call identifier argument_list argument_list ( identifier , string ) ) string \" \" \" \" , identifier ( identifier with : comparison_operator identifier is not none none not is identifier if comment expression_statement call call attribute argument_list argument_list ( identifier , identifier ) ) identifier , identifier ( attribute identifier . identifier identifier . identifier expression_statement assignment assignment identifier = call call attribute argument_list argument_list ( keyword_argument , keyword_argument , keyword_argument ) ) keyword_argument identifier = string string \" \" \" \" = identifier , keyword_argument identifier = identifier identifier = identifier , keyword_argument identifier = identifier identifier = identifier ( attribute identifier . identifier identifier . identifier = identifier comment if_statement if comparison_operator : block block expression_statement if_statement if_statement if identifier : block block expression_statement expression_statement call call identifier argument_list argument_list ( string , identifier ) ) identifier , string \" \" \" \" ( identifier : identifier if expression_statement assignment assignment identifier = call call identifier argument_list argument_list ( call ) ) call identifier argument_list argument_list ( call ) ) call attribute argument_list argument_list ( call ) ) call identifier argument_list argument_list ( identifier ) ) identifier ( identifier ( attribute identifier . identifier identifier . identifier ( identifier ( identifier = identifier : comparison_operator identifier is none none is identifier if comment for_statement for identifier in call : block block if_statement comment for_statement for_statement for identifier in call : block block expression_statement expression_statement if_statement if_statement if comparison_operator : comment block else_clause else_clause else : comment block block expression_statement expression_statement expression_statement call call attribute argument_list argument_list ( identifier ) ) identifier ( attribute identifier . identifier identifier . identifier expression_statement call call attribute argument_list argument_list ( subscript ) ) subscript call [ integer ] ] integer [ call attribute argument_list argument_list ( identifier , keyword_argument ) ) keyword_argument identifier = identifier identifier = identifier , identifier ( attribute identifier . identifier identifier . identifier ( attribute identifier . identifier identifier . identifier comment : else block if_statement if_statement if identifier : block block expression_statement expression_statement call call identifier argument_list argument_list ( call ) ) call attribute argument_list argument_list ( identifier , conditional_expression ) ) conditional_expression string if comparison_operator else string string \" \" \" \" else comparison_operator call < integer integer < call identifier argument_list argument_list ( identifier ) ) identifier ( identifier if string \" \" \" \" , identifier ( attribute string . identifier identifier . string \" \" \" \" ( identifier : identifier if comment : comparison_operator call != integer integer != call identifier argument_list argument_list ( identifier ) ) identifier ( identifier if expression_statement assignment assignment identifier = call call attribute argument_list argument_list ( identifier ) ) identifier ( attribute identifier . identifier identifier . identifier = identifier expression_statement assignment assignment identifier = call call attribute argument_list argument_list ( identifier ) ) identifier ( attribute identifier . identifier identifier . identifier = identifier : call identifier argument_list argument_list ( call ) ) call attribute argument_list argument_list ( identifier , identifier ) ) identifier , identifier ( attribute attribute . identifier identifier . attribute identifier . identifier identifier . identifier ( identifier in identifier for comment if_statement if not_operator : block block continue_statement continue_statement continue continue : not_operator not call call attribute argument_list argument_list ( call ) ) call attribute argument_list argument_list ( identifier , identifier ) ) identifier , identifier ( attribute attribute . identifier identifier . attribute identifier . identifier identifier . identifier ( attribute attribute . identifier identifier . attribute identifier . identifier identifier . identifier not if : call attribute argument_list argument_list ( identifier ) ) identifier ( attribute identifier . identifier identifier . identifier in identifier for comment expression_statement assignment assignment identifier = list list [ ] ] [ = identifier expression_statement assignment assignment identifier = list list [ ] ] [ = identifier expression_statement string string \" \" \" \" : parameters ( identifier , default_parameter , default_parameter , default_parameter , default_parameter ) ) default_parameter identifier = false false = identifier , default_parameter identifier = string string \" \" \" \" = identifier , default_parameter identifier = none none = identifier , default_parameter identifier = none none = identifier , identifier ( identifier def EOS\n"
     ]
    }
   ],
   "source": [
    "def encode(nl_sentences, pl_sentences, nl_dict, pl_dict, sort_by_len=False):\n",
    "    '''\n",
    "        Encode the sequences. \n",
    "    '''\n",
    "    length = len(nl_sentences)\n",
    "    out_nl_sentences = [[nl_dict.get(w, 0) for w in sent] for sent in nl_sentences]\n",
    "    out_pl_sentences = [[pl_dict.get(w, 0) for w in sent] for sent in pl_sentences]\n",
    "\n",
    "    # sort sentences by english lengths\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "       \n",
    "    # 把中文和英文按照同样的顺序排序\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(out_nl_sentences)\n",
    "        out_nl_sentences = [out_nl_sentences[i] for i in sorted_index]\n",
    "        out_pl_sentences = [out_pl_sentences[i] for i in sorted_index]\n",
    "        \n",
    "    return out_nl_sentences, out_pl_sentences\n",
    "\n",
    "train_nl, train_pl = encode(nl, pl, nl_dict, pl_dict)\n",
    "# print(train_nl[0])\n",
    "inv_pl_dict = {v: k for k, v in pl_dict.items()}\n",
    "inv_nl_dict = {v: k for k, v in nl_dict.items()}\n",
    "# k = 0\n",
    "# print(\" \".join([inv_nl_dict[i] for i in train_nl[k]]))\n",
    "# print(\" \".join([inv_pl_dict[i] for i in train_pl[k]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatches(n, minibatch_size, shuffle=True):\n",
    "    idx_list = np.arange(0, n, minibatch_size) # [0, 1, ..., n-1]\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    for idx in idx_list:\n",
    "        minibatches.append(np.arange(idx, min(idx + minibatch_size, n)))\n",
    "    return minibatches\n",
    "\n",
    "def prepare_data(seqs):\n",
    "    lengths = [len(seq) for seq in seqs]\n",
    "    n_samples = len(seqs)\n",
    "    max_len = np.max(lengths)\n",
    "\n",
    "    x = np.zeros((n_samples, max_len)).astype('int32')\n",
    "    x_lengths = np.array(lengths).astype(\"int32\")\n",
    "    for idx, seq in enumerate(seqs):\n",
    "        x[idx, :lengths[idx]] = seq\n",
    "    return x, x_lengths #x_mask\n",
    "\n",
    "def gen_examples(nl_sentences, pl_sentences, batch_size):\n",
    "    minibatches = get_minibatches(len(nl_sentences), batch_size)\n",
    "    all_ex = []\n",
    "    for minibatch in minibatches:\n",
    "        mb_nl_sentences = [nl_sentences[t] for t in minibatch]\n",
    "        mb_pl_sentences = [pl_sentences[t] for t in minibatch]\n",
    "        mb_x, mb_x_len = prepare_data(mb_nl_sentences)\n",
    "        mb_y, mb_y_len = prepare_data(mb_pl_sentences)\n",
    "        all_ex.append((mb_x, mb_x_len, mb_y, mb_y_len))\n",
    "    return all_ex\n",
    "\n",
    "batch_size = 64\n",
    "train_data = gen_examples(train_nl, train_pl, batch_size)\n",
    "random.shuffle(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, enc_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(enc_hidden_size * 2, dec_hidden_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        sorted_len, sorted_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[sorted_idx.long()]\n",
    "        embedded = self.dropout(self.embed(x_sorted))\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        packed_out, hid = self.rnn(packed_embedded)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        out = out[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "        \n",
    "        hid = torch.cat([hid[-2], hid[-1]], dim=1)\n",
    "        hid = torch.tanh(self.fc(hid)).unsqueeze(0)\n",
    "\n",
    "        return out, hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.linear_in = nn.Linear(enc_hidden_size*2, dec_hidden_size, bias=False)\n",
    "        self.linear_out = nn.Linear(enc_hidden_size*2 + dec_hidden_size, dec_hidden_size)\n",
    "        \n",
    "    def forward(self, output, context, mask):\n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        # context: batch_size, context_len, 2*enc_hidden_size\n",
    "    \n",
    "        batch_size = output.size(0)\n",
    "        output_len = output.size(1)\n",
    "        input_len = context.size(1)\n",
    "        \n",
    "        context_in = self.linear_in(context.view(batch_size*input_len, -1)).view(                \n",
    "            batch_size, input_len, -1) # batch_size, context_len, dec_hidden_size\n",
    "        \n",
    "        # context_in.transpose(1,2): batch_size, dec_hidden_size, context_len \n",
    "        # output: batch_size, output_len, dec_hidden_size\n",
    "        attn = torch.bmm(output, context_in.transpose(1,2)) \n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        attn.data.masked_fill(mask, -1e6)\n",
    "\n",
    "        attn = F.softmax(attn, dim=2) \n",
    "        # batch_size, output_len, context_len\n",
    "\n",
    "        context = torch.bmm(attn, context) \n",
    "        # batch_size, output_len, enc_hidden_size\n",
    "        \n",
    "        output = torch.cat((context, output), dim=2) # batch_size, output_len, hidden_size*2\n",
    "\n",
    "        output = output.view(batch_size*output_len, -1)\n",
    "        output = torch.tanh(self.linear_out(output))\n",
    "        output = output.view(batch_size, output_len, -1)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, enc_hidden_size, dec_hidden_size, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = Attention(enc_hidden_size, dec_hidden_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(dec_hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def create_mask(self, x_len, y_len):\n",
    "        # a mask of shape x_len * y_len\n",
    "        device = x_len.device\n",
    "        max_x_len = x_len.max()\n",
    "        max_y_len = y_len.max()\n",
    "        x_mask = torch.arange(max_x_len, device=x_len.device)[None, :] < x_len[:, None]\n",
    "        y_mask = torch.arange(max_y_len, device=x_len.device)[None, :] < y_len[:, None]\n",
    "        mask = (1 - x_mask[:, :, None] * y_mask[:, None, :]).byte()\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, ctx, ctx_lengths, y, y_lengths, hid):\n",
    "        sorted_len, sorted_idx = y_lengths.sort(0, descending=True)\n",
    "        y_sorted = y[sorted_idx.long()]\n",
    "        hid = hid[:, sorted_idx.long()]\n",
    "        \n",
    "        y_sorted = self.dropout(self.embed(y_sorted)) # batch_size, output_length, embed_size\n",
    "\n",
    "        packed_seq = nn.utils.rnn.pack_padded_sequence(y_sorted, sorted_len.long().cpu().data.numpy(), batch_first=True)\n",
    "        out, hid = self.rnn(packed_seq, hid)\n",
    "        unpacked, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "        output_seq = unpacked[original_idx.long()].contiguous()\n",
    "        hid = hid[:, original_idx.long()].contiguous()\n",
    "\n",
    "        mask = self.create_mask(y_lengths, ctx_lengths)\n",
    "\n",
    "        output, attn = self.attention(output_seq, ctx, mask)\n",
    "        output = F.log_softmax(self.out(output), -1)\n",
    "        \n",
    "        return output, hid, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x, x_lengths, y, y_lengths):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        output, hid, attn = self.decoder(ctx=encoder_out, \n",
    "                    ctx_lengths=x_lengths,\n",
    "                    y=y,\n",
    "                    y_lengths=y_lengths,\n",
    "                    hid=hid)\n",
    "        return output, attn\n",
    "    \n",
    "    def translate(self, x, x_lengths, y, max_length=100):\n",
    "        encoder_out, hid = self.encoder(x, x_lengths)\n",
    "        preds = []\n",
    "        batch_size = x.shape[0]\n",
    "        attns = []\n",
    "        for i in range(max_length):\n",
    "            output, hid, attn = self.decoder(ctx=encoder_out, \n",
    "                    ctx_lengths=x_lengths,\n",
    "                    y=y,\n",
    "                    y_lengths=torch.ones(batch_size).long().to(y.device),\n",
    "                    hid=hid)\n",
    "            y = output.max(2)[1].view(batch_size, 1)\n",
    "            preds.append(y)\n",
    "            attns.append(attn)\n",
    "        return torch.cat(preds, 1), torch.cat(attns, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.2\n",
    "embed_size = hidden_size = 100\n",
    "encoder = Encoder(vocab_size=en_total_words,\n",
    "                       embed_size=embed_size,\n",
    "                      enc_hidden_size=hidden_size,\n",
    "                       dec_hidden_size=hidden_size,\n",
    "                      dropout=dropout)\n",
    "decoder = Decoder(vocab_size=cn_total_words,\n",
    "                      embed_size=embed_size,\n",
    "                      enc_hidden_size=hidden_size,\n",
    "                       dec_hidden_size=hidden_size,\n",
    "                      dropout=dropout)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "model = model.to(device)\n",
    "loss_fn = LanguageModelCriterion().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_data, num_epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
